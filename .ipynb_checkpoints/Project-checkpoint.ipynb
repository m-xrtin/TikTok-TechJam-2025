{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ba38d3-75e8-48a2-abc9-fe9831be5970",
   "metadata": {},
   "source": [
    "# Hello! ðŸ‘‹  \n",
    "Welcome to **Compile & Conquer's** workspace.\n",
    "\n",
    "Our project utilizes a combination of libraries and APIs to tackle the problem of spam review detection.  \n",
    "Below is a brief overview of our pipeline:\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”‘ Training vs Inference\n",
    "\n",
    "ðŸ‘‰ **Training Pipeline (done by us):**\n",
    "- Standardize raw datasets into workable CSV format\n",
    "- Preprocess and clean the data\n",
    "- Use both OpenAI and VADER for pseudolabelling\n",
    "- Train CatBoost with 10-fold cross-validation\n",
    "- Save models + metadata\n",
    "\n",
    "ðŸ‘‰ **Inference Pipeline (for judges / new data):**\n",
    "- Standardize and preprocess new input\n",
    "- Add VADER sentiment for extra accuracy\n",
    "- Load pre-trained CatBoost models\n",
    "- Predict spam vs ham  \n",
    "- Save results to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77c66c2-8902-4a63-a021-26ce9def6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "import random\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "from src.parse_file import *\n",
    "from src.ucsd_json_standardization import *\n",
    "from src.standardization import *\n",
    "from src.helpers import *\n",
    "from src.preprocess import *\n",
    "from src.vader_function import *\n",
    "from src.inference import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11aea42-5cca-441e-9fa8-c3ca0a6a174f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "We need to set some directories so that our program can access all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2f584b-98ff-499b-b64e-144506d272af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "INPUT_FOLDER = os.path.join(PROJECT_ROOT, \"input\")\n",
    "DATA_FOLDER = os.path.join(PROJECT_ROOT, \"data\")\n",
    "OUTPUT_FOLDER = os.path.join(PROJECT_ROOT, \"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac5330e-ccee-4dea-b915-5a1c8b67a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is successfully standardized!\n"
     ]
    }
   ],
   "source": [
    "input_file = \"test.json\" # Feel free to change! Though have to have the file of interest in the input folder of the project directory.\n",
    "output_file = standardize_file(input_file)\n",
    "output_path = os.path.join(DATA_FOLDER, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c490d-5bbd-4930-9d19-0b66a318f6f5",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Youâ€™re welcome to review the standardization step, but weâ€™ll now move on to preprocessing.\n",
    "\n",
    "Our project supports two different approaches to standardization, depending on the type of file we receive:\n",
    "\n",
    "UCSD Google Review Dataset: Since this dataset is already well-structured, we use a streamlined, faster pipeline.\n",
    "\n",
    "Other datasets: To ensure scalability and robustness, we also integrate OpenAI to assist with standardization. Open AI is very versatile for all kinds of files, albeit slower runtime... ðŸ¥º\n",
    "\n",
    "This dual approach ensures our pipeline works efficiently with clean data while remaining flexible enough to process real-world datasets that may not be as polished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623d87c1-ef5a-41e2-9dd7-c9498e40e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 10 rows into c:\\Users\\hanya\\Desktop\\TikTok TechJam\\TikTok-TechJam-2025\\data\\test_standardized.csv\n",
      "Preprocessing complete. Saved to c:\\Users\\hanya\\Desktop\\TikTok TechJam\\TikTok-TechJam-2025\\data\\test_standardized_preprocessed.csv\n",
      "Final columns: ['business_name', 'text', 'sentiment_category', 'gmap_id', 'rating', 'time', 'user_name', 'user_id']\n",
      "VADER sentiment scoring complete. Saved to c:\\Users\\hanya\\Desktop\\TikTok TechJam\\TikTok-TechJam-2025\\data\\test_standardized_final.csv\n"
     ]
    }
   ],
   "source": [
    "base_name = os.path.splitext(output_file)[0]  # standardized base name\n",
    "csv_path = os.path.join(DATA_FOLDER, base_name + \".csv\")\n",
    "json_to_csv_from_data(output_path, csv_path)\n",
    "_, preprocessed_csv = preprocess_file(base_name)\n",
    "_, final_csv = VADER_Sentiment_Score(base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1392f1-7f4b-4d1c-8bfd-f46b87602cf1",
   "metadata": {},
   "source": [
    "# Training\n",
    "Our dataset is now fully standardized and ready to be plugged into the model!\n",
    "In the preprocessing stage, we remove potentially problematic rows such as duplicate entries and non sensible values.\n",
    "\n",
    "We also enrich the dataset with VADER sentiment scores, adding new attributes that can help the model capture more nuance in the reviews. This should improve both the robustness and overall accuracy of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "249d3ba8-8088-47ae-90cc-dd79e22f2627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_FOLDER = c:\\Users\\hanya\\Desktop\\TikTok TechJam\\TikTok-TechJam-2025\\data\n",
      "OUTPUT_FOLDER = c:\\Users\\hanya\\Desktop\\TikTok TechJam\\TikTok-TechJam-2025\\outputs\n",
      "Inference complete. Results saved to c:\\Users\\hanya\\Desktop\\TikTok TechJam\\TikTok-TechJam-2025\\data\\test_standardized_results.csv\n",
      "Summary: 0 likely spam, 10 likely ham out of 10 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Final Step!\n",
    "_, results_csv = run_inference(base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245ee2c",
   "metadata": {},
   "source": [
    "# Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436e0e87-e785-47b7-833d-4dcdb9347e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_category</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>user_name</th>\n",
       "      <th>probability</th>\n",
       "      <th>decision</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>1566331951619</td>\n",
       "      <td>5</td>\n",
       "      <td>We always stay here when in Valdez for silver ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.169097</td>\n",
       "      <td>0</td>\n",
       "      <td>likely ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>1503373018846</td>\n",
       "      <td>5</td>\n",
       "      <td>This was an amazing RV camping experience with...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.142077</td>\n",
       "      <td>0</td>\n",
       "      <td>likely ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>1410062370985</td>\n",
       "      <td>5</td>\n",
       "      <td>Spent the summer of 2011. Had a wonderful time...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.143206</td>\n",
       "      <td>0</td>\n",
       "      <td>likely ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1495241580499</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife and I have stayed at Bear Creek severa...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.317292</td>\n",
       "      <td>0</td>\n",
       "      <td>likely ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>1504917982385</td>\n",
       "      <td>5</td>\n",
       "      <td>Great campground for the price. Nice hot showe...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.163952</td>\n",
       "      <td>0</td>\n",
       "      <td>likely ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vader_category           time  rating  \\\n",
       "0       positive  1566331951619       5   \n",
       "1       positive  1503373018846       5   \n",
       "2       positive  1410062370985       5   \n",
       "3        neutral  1495241580499       5   \n",
       "4       positive  1504917982385       5   \n",
       "\n",
       "                                                text user_name  probability  \\\n",
       "0  We always stay here when in Valdez for silver ...   unknown     0.169097   \n",
       "1  This was an amazing RV camping experience with...   unknown     0.142077   \n",
       "2  Spent the summer of 2011. Had a wonderful time...   unknown     0.143206   \n",
       "3  My wife and I have stayed at Bear Creek severa...   unknown     0.317292   \n",
       "4  Great campground for the price. Nice hot showe...   unknown     0.163952   \n",
       "\n",
       "   decision     verdict  \n",
       "0         0  likely ham  \n",
       "1         0  likely ham  \n",
       "2         0  likely ham  \n",
       "3         0  likely ham  \n",
       "4         0  likely ham  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_name = base_name + \"_results.csv\"\n",
    "result_path = os.path.join(OUTPUT_FOLDER, result_name)\n",
    "\n",
    "df = pd.read_csv(result_path)\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
