{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ba38d3-75e8-48a2-abc9-fe9831be5970",
   "metadata": {},
   "source": [
    "# Hello! ðŸ‘‹  \n",
    "Welcome to **Compile & Conquer's** workspace.\n",
    "\n",
    "Our project utilizes a combination of libraries and APIs to tackle the problem of spam review detection.  \n",
    "Below is a brief overview of our pipeline:\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”‘ Training vs Inference\n",
    "\n",
    "ðŸ‘‰ **Training Pipeline (done by us):**\n",
    "- Standardize raw datasets into workable CSV format\n",
    "- Preprocess and clean the data\n",
    "- Use both OpenAI and VADER for pseudolabelling\n",
    "- Train CatBoost with 10-fold cross-validation\n",
    "- Save models + metadata\n",
    "\n",
    "ðŸ‘‰ **Inference Pipeline (for judges / new data):**\n",
    "- Standardize and preprocess new input\n",
    "- Add VADER sentiment for extra accuracy\n",
    "- Load pre-trained CatBoost models\n",
    "- Predict spam vs ham  \n",
    "- Save results to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c66c2-8902-4a63-a021-26ce9def6f19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ucsd_json_standardization'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparse_file\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mucsd_json_standardization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstandardization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocess\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hanya\\Desktop\\TikTok TechJam\\TikTok-TechJam-2025\\src\\standardization.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mucsd_json_standardization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mparse_file\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ucsd_json_standardization'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "import random\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "from src.parse_file import *\n",
    "from src.ucsd_json_standardization import *\n",
    "from src.standardization import *\n",
    "from src.helpers import *\n",
    "from src.preprocess import *\n",
    "from src.Vader_function import *\n",
    "from src.inference import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11aea42-5cca-441e-9fa8-c3ca0a6a174f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "We need to set some directories so that our program can access all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f584b-98ff-499b-b64e-144506d272af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "INPUT_FOLDER = os.path.join(PROJECT_ROOT, \"input\")\n",
    "DATA_FOLDER = os.path.join(PROJECT_ROOT, \"data\")\n",
    "OUTPUT_FOLDER = os.path.join(PROJECT_ROOT, \"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac5330e-ccee-4dea-b915-5a1c8b67a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"test.json\" # Feel free to change! Though have to have the file of interest in the input folder of the project directory.\n",
    "output_file = standardize_file(input_file)\n",
    "output_path = os.path.join(DATA_FOLDER, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c490d-5bbd-4930-9d19-0b66a318f6f5",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Youâ€™re welcome to review the standardization step, but weâ€™ll now move on to preprocessing.\n",
    "\n",
    "Our project supports two different approaches to standardization, depending on the type of file we receive:\n",
    "\n",
    "UCSD Google Review Dataset: Since this dataset is already well-structured, we use a streamlined, faster pipeline.\n",
    "\n",
    "Other datasets: To ensure scalability and robustness, we also integrate OpenAI to assist with standardization. Open AI is very versatile for all kinds of files, albeit slower runtime... ðŸ¥º\n",
    "\n",
    "This dual approach ensures our pipeline works efficiently with clean data while remaining flexible enough to process real-world datasets that may not be as polished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d87c1-ef5a-41e2-9dd7-c9498e40e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = os.path.splitext(output_file)[0]  # standardized base name\n",
    "csv_path = os.path.join(DATA_FOLDER, base_name + \".csv\")\n",
    "json_to_csv_from_data(output_path, csv_path)\n",
    "_, preprocessed_csv = preprocess_file(base_name)\n",
    "_, final_csv = VADER_Sentiment_Score(base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1392f1-7f4b-4d1c-8bfd-f46b87602cf1",
   "metadata": {},
   "source": [
    "# Training\n",
    "Our dataset is now fully standardized and ready to be plugged into the model!\n",
    "In the preprocessing stage, we remove potentially problematic rows such as duplicate entries and non sensible values.\n",
    "\n",
    "We also enrich the dataset with VADER sentiment scores, adding new attributes that can help the model capture more nuance in the reviews. This should improve both the robustness and overall accuracy of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d3ba8-8088-47ae-90cc-dd79e22f2627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final Step!\n",
    "_, results_csv = run_inference(base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245ee2c",
   "metadata": {},
   "source": [
    "# Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e0e87-e785-47b7-833d-4dcdb9347e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_name = base_name + \"_results.csv\"\n",
    "result_path = os.path.join(OUTPUT_FOLDER, result_name)\n",
    "\n",
    "df = pd.read_csv(result_path)\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
